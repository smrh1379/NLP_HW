{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sklearn_crfsuite\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in c:\\users\\smrh1\\.conda\\envs\\tensorflow_gpu_cnn\\lib\\site-packages (from sklearn_crfsuite) (0.9.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.7 in c:\\users\\smrh1\\.conda\\envs\\tensorflow_gpu_cnn\\lib\\site-packages (from sklearn_crfsuite) (0.9.10)\n",
            "Requirement already satisfied: tqdm>=2.0 in c:\\users\\smrh1\\.conda\\envs\\tensorflow_gpu_cnn\\lib\\site-packages (from sklearn_crfsuite) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in c:\\users\\smrh1\\.conda\\envs\\tensorflow_gpu_cnn\\lib\\site-packages (from sklearn_crfsuite) (1.4.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\smrh1\\.conda\\envs\\tensorflow_gpu_cnn\\lib\\site-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\smrh1\\.conda\\envs\\tensorflow_gpu_cnn\\lib\\site-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.9.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\smrh1\\.conda\\envs\\tensorflow_gpu_cnn\\lib\\site-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\smrh1\\.conda\\envs\\tensorflow_gpu_cnn\\lib\\site-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.23.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\smrh1\\.conda\\envs\\tensorflow_gpu_cnn\\lib\\site-packages (from tqdm>=2.0->sklearn_crfsuite) (0.4.6)\n",
            "Installing collected packages: sklearn_crfsuite\n",
            "Successfully installed sklearn_crfsuite-0.5.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "utvBSx6OWc5a",
        "outputId": "36597c1a-9de7-4fe7-f339-49de46e13cd9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "ERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\n",
            "ERROR: No matching distribution found for pickle\n",
            "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\smrh1\\appdata\\roaming\\python\\python39\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install joblib"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Abt9JTVOWc5e",
        "outputId": "334908f9-fce5-431a-c4e9-e50e3b584628"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\smrh1\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\smrh1\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Accuracy: 0.9614500463369721\n",
            "Precision: 0.9614500463369721\n",
            "Recall: 0.9614500463369721\n",
            "Micro F1: 0.9614500463369721\n",
            "Macro F1: 0.5265026830256874\n",
            "Fold 2\n",
            "Accuracy: 0.9608558905632255\n",
            "Precision: 0.9608558905632255\n",
            "Recall: 0.9608558905632255\n",
            "Micro F1: 0.9608558905632255\n",
            "Macro F1: 0.5081435438696298\n",
            "Fold 3\n",
            "Accuracy: 0.9493786442075505\n",
            "Precision: 0.9493786442075505\n",
            "Recall: 0.9493786442075505\n",
            "Micro F1: 0.9493786442075505\n",
            "Macro F1: 0.512470680999912\n",
            "Fold 4\n",
            "Accuracy: 0.9591663122075712\n",
            "Precision: 0.9591663122075712\n",
            "Recall: 0.9591663122075712\n",
            "Micro F1: 0.9591663122075712\n",
            "Macro F1: 0.5087991167349745\n",
            "Fold 5\n",
            "Accuracy: 0.9586858555022533\n",
            "Precision: 0.9586858555022533\n",
            "Recall: 0.9586858555022533\n",
            "Micro F1: 0.9586858555022533\n",
            "Macro F1: 0.5153474259456265\n",
            "Fold 6\n",
            "Accuracy: 0.9581215101258438\n",
            "Precision: 0.9581215101258438\n",
            "Recall: 0.9581215101258438\n",
            "Micro F1: 0.9581215101258438\n",
            "Macro F1: 0.5123277108693453\n",
            "Fold 7\n",
            "Accuracy: 0.9531073190603359\n",
            "Precision: 0.9531073190603359\n",
            "Recall: 0.9531073190603359\n",
            "Micro F1: 0.9531073190603359\n",
            "Macro F1: 0.5306782807167778\n",
            "Fold 8\n",
            "Accuracy: 0.9500947655945148\n",
            "Precision: 0.9500947655945148\n",
            "Recall: 0.9500947655945148\n",
            "Micro F1: 0.9500947655945148\n",
            "Macro F1: 0.4797659682063131\n",
            "Fold 9\n",
            "Accuracy: 0.9524243273542601\n",
            "Precision: 0.9524243273542601\n",
            "Recall: 0.9524243273542601\n",
            "Micro F1: 0.9524243273542601\n",
            "Macro F1: 0.5250475070555005\n",
            "Fold 10\n",
            "Accuracy: 0.9584671348052606\n",
            "Precision: 0.9584671348052606\n",
            "Recall: 0.9584671348052606\n",
            "Micro F1: 0.9584671348052606\n",
            "Macro F1: 0.5150815653888479\n",
            "\n",
            "Metrics Mean and Standard Deviation:\n",
            "Accuracy - Mean: 0.9561751805757789, Std: 0.004250528106414168\n",
            "Precision - Mean: 0.9561751805757789, Std: 0.004250528106414168\n",
            "Recall - Mean: 0.9561751805757789, Std: 0.004250528106414168\n",
            "F1_micro - Mean: 0.9561751805757789, Std: 0.004250528106414168\n",
            "F1_macro - Mean: 0.5134164482812615, Std: 0.01339612303045077\n",
            "Confusion_matrix - Mean: 203.04238227146814, Std: 3557.277400215207\n",
            "\n",
            "Test Set Metrics:\n",
            "Confusion Matrix:\n",
            "[[77031   291    63   144   149    44    41    26    19     8    11    69\n",
            "    368    44     1     5     3    36    57]\n",
            " [  350   693     1     0     0     0     0     0     0     0     0     0\n",
            "      1     0     0     0     0     0     0]\n",
            " [   79     1   175     0     0     2     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]\n",
            " [  111     0     0   310     0     0     0     5     0     0     0     0\n",
            "      1     0     0     0     0     0     0]\n",
            " [   99     0     0     0   283     1     0     0    17     0     0     0\n",
            "      0     0     0     0     0     0     0]\n",
            " [   86     0     0     0     0   110     1     0     2     0     0     0\n",
            "      0     2     0     0     0     0     0]\n",
            " [   48     0     0     0     0     0   185     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]\n",
            " [  103     0     0     2     1     0     0    65     0     0     1     0\n",
            "      0     0     0     0     0     0     0]\n",
            " [  139     0     0     0     5     0     0     2    90     0     1     0\n",
            "      0     0     0     0     0     0     0]\n",
            " [   28     0     0     0     0     0     0     0     0    16     1     0\n",
            "      0     0     0     0     0     0     0]\n",
            " [   44     0     0     0     0     0     0     0     0     0    32     0\n",
            "      0     0     0     0     0     0     0]\n",
            " [  170     0     0     0     0     0     0     0     0     0     0   158\n",
            "      2     1     0     0     0     0     0]\n",
            " [  321     0     0     0     0     0     0     0     0     0     0     4\n",
            "    552     0     0     0     0     0     0]\n",
            " [   99     0     1     0     0     3     0     0     0     0     0     0\n",
            "      0    36     0     0     0     0     0]\n",
            " [   11     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     3     0     0     0     0]\n",
            " [   70     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     1     1     2     0]\n",
            " [   57     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     3     0     0]\n",
            " [  269     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     1     0    36     0]\n",
            " [  252     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     1     1    26]]\n",
            "Accuracy: 0.9547879977029097\n",
            "Precision: 0.9547879977029097\n",
            "Recall: 0.9547879977029097\n",
            "Micro F1: 0.9547879977029097\n",
            "Macro F1: 0.4945181995685435\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import numpy as np\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import metrics\n",
        "import joblib\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def read_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "def parse_ann(ann_content):\n",
        "    annotations = []\n",
        "    for line in ann_content.strip().split('\\n'):\n",
        "        if line.startswith('T'):\n",
        "            parts = line.split('\\t')\n",
        "            ann_id = parts[0]\n",
        "            label_info = parts[1]\n",
        "            text = parts[2]\n",
        "            label_info_parts = label_info.split()\n",
        "            label = label_info_parts[0]\n",
        "            start = int(label_info_parts[1].split(';')[0])\n",
        "            end = int(label_info_parts[2].split(';')[0])\n",
        "            annotations.append({\n",
        "                'id': ann_id,\n",
        "                'label': label,\n",
        "                'start': start,\n",
        "                'end': end,\n",
        "                'text': text\n",
        "            })\n",
        "    return annotations\n",
        "\n",
        "def preprocess_text(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words and token not in string.punctuation]\n",
        "    return filtered_tokens\n",
        "\n",
        "def format_input(text, annotations):\n",
        "    tokens = word_tokenize(text)\n",
        "    token_annotations = ['O'] * len(tokens)\n",
        "\n",
        "    for ann in annotations:\n",
        "        ann_tokens = word_tokenize(ann['text'])\n",
        "        ann_label = ann['label']\n",
        "        start = ann['start']\n",
        "        end = ann['end']\n",
        "\n",
        "        for i in range(len(tokens)):\n",
        "            if tokens[i:i+len(ann_tokens)] == ann_tokens:\n",
        "                token_annotations[i] = f'B-{ann_label}'\n",
        "                for j in range(1, len(ann_tokens)):\n",
        "                    token_annotations[i + j] = f'I-{ann_label}'\n",
        "                break\n",
        "\n",
        "    return tokens, token_annotations\n",
        "\n",
        "def process_files(txt_file, ann_file):\n",
        "    text = read_file(txt_file)\n",
        "    ann_content = read_file(ann_file)\n",
        "    annotations = parse_ann(ann_content)\n",
        "    tokens, labels = format_input(text, annotations)\n",
        "    return tokens, labels\n",
        "\n",
        "tokend_text = []\n",
        "cor_labels = []\n",
        "\n",
        "def process_all_files(directory):\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            txt_file = os.path.join(directory, filename)\n",
        "            ann_file = txt_file.replace(\".txt\", \".ann\")\n",
        "            if os.path.exists(ann_file):\n",
        "                tokens, labels = process_files(txt_file, ann_file)\n",
        "                tokend_text.append(tokens)\n",
        "                cor_labels.append(labels)\n",
        "\n",
        "directory = 'n2c2/n2c2/part2'\n",
        "process_all_files(directory)\n",
        "\n",
        "labels_list = [\"O\", \"B-Drug\", \"I-Drug\", \"B-Strength\", \"I-Strength\", \"B-Form\", \"I-Form\", \"B-Dosage\", \"I-Dosage\",\n",
        "               \"B-Duration\", \"I-Duration\", \"B-Frequency\", \"I-Frequency\", \"B-Route\", \"I-Route\", \"B-ADE\", \"I-ADE\",\n",
        "               \"B-Reason\", \"I-Reason\"]\n",
        "\n",
        "label_map = {label: i for i, label in enumerate(labels_list)}\n",
        "id2label = {i: label for i, label in enumerate(labels_list)}\n",
        "\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return sent\n",
        "\n",
        "X = [sent2features(s) for s in tokend_text]\n",
        "y = [sent2labels(l) for l in cor_labels]\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(tokend_text, cor_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "all_metrics = {\n",
        "    'accuracy': [],\n",
        "    'precision': [],\n",
        "    'recall': [],\n",
        "    'f1_micro': [],\n",
        "    'f1_macro': [],\n",
        "    'confusion_matrix': []\n",
        "}\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(train_texts)):\n",
        "    print(f\"Fold {fold + 1}\")\n",
        "\n",
        "    X_train = [sent2features(train_texts[i]) for i in train_index]\n",
        "    y_train = [sent2labels(train_labels[i]) for i in train_index]\n",
        "    X_val = [sent2features(train_texts[i]) for i in val_index]\n",
        "    y_val = [sent2labels(train_labels[i]) for i in val_index]\n",
        "\n",
        "    crf = sklearn_crfsuite.CRF(\n",
        "        algorithm='lbfgs',\n",
        "        c1=0.1,\n",
        "        c2=0.1,\n",
        "        max_iterations=100,\n",
        "        all_possible_transitions=False\n",
        "    )\n",
        "    crf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = crf.predict(X_val)\n",
        "\n",
        "    flat_true_labels = [item for sublist in y_val for item in sublist]\n",
        "    flat_pred_labels = [item for sublist in y_pred for item in sublist]\n",
        "\n",
        "    cm = confusion_matrix(flat_true_labels, flat_pred_labels, labels=labels_list)\n",
        "\n",
        "    accuracy = accuracy_score(flat_true_labels, flat_pred_labels)\n",
        "    precision, recall, f1_micro, _ = precision_recall_fscore_support(flat_true_labels, flat_pred_labels, average='micro')\n",
        "    _, _, f1_macro, _ = precision_recall_fscore_support(flat_true_labels, flat_pred_labels, average='macro')\n",
        "\n",
        "    all_metrics['accuracy'].append(accuracy)\n",
        "    all_metrics['precision'].append(precision)\n",
        "    all_metrics['recall'].append(recall)\n",
        "    all_metrics['f1_micro'].append(f1_micro)\n",
        "    all_metrics['f1_macro'].append(f1_macro)\n",
        "    all_metrics['confusion_matrix'].append(cm)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"Micro F1: {f1_micro}\")\n",
        "    print(f\"Macro F1: {f1_macro}\")\n",
        "\n",
        "metrics_mean_std = {metric: (np.mean(all_metrics[metric]), np.std(all_metrics[metric])) for metric in all_metrics}\n",
        "\n",
        "print(\"\\nMetrics Mean and Standard Deviation:\")\n",
        "for metric, (mean, std) in metrics_mean_std.items():\n",
        "    print(f\"{metric.capitalize()} - Mean: {mean}, Std: {std}\")\n",
        "\n",
        "X_test = [sent2features(s) for s in test_texts]\n",
        "y_test = [sent2labels(l) for l in test_labels]\n",
        "\n",
        "y_pred_test = crf.predict(X_test)\n",
        "\n",
        "flat_true_labels_test = [item for sublist in y_test for item in sublist]\n",
        "flat_pred_labels_test = [item for sublist in y_pred_test for item in sublist]\n",
        "\n",
        "cm_test = confusion_matrix(flat_true_labels_test, flat_pred_labels_test, labels=labels_list)\n",
        "\n",
        "accuracy_test = accuracy_score(flat_true_labels_test, flat_pred_labels_test)\n",
        "precision_test, recall_test, f1_micro_test, _ = precision_recall_fscore_support(flat_true_labels_test, flat_pred_labels_test, average='micro')\n",
        "_, _, f1_macro_test, _ = precision_recall_fscore_support(flat_true_labels_test, flat_pred_labels_test, average='macro')\n",
        "\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "print(f\"Confusion Matrix:\\n{cm_test}\")\n",
        "print(f\"Accuracy: {accuracy_test}\")\n",
        "print(f\"Precision: {precision_test}\")\n",
        "print(f\"Recall: {recall_test}\")\n",
        "print(f\"Micro F1: {f1_micro_test}\")\n",
        "print(f\"Macro F1: {f1_macro_test}\")\n",
        "\n",
        "joblib.dump(crf, 'crf_model.pkl')\n",
        "\n",
        "crf = joblib.load('crf_model.pkl')\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Pi4t-sYgWc5f",
        "outputId": "e6bc67e2-1734-4273-a16e-e8ded8dac0e2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-ADE       0.14      0.01      0.02        74\n",
            "    B-Dosage       0.66      0.38      0.48       172\n",
            "      B-Drug       0.70      0.66      0.68      1045\n",
            "  B-Duration       0.67      0.36      0.46        45\n",
            "      B-Form       0.69      0.55      0.61       201\n",
            " B-Frequency       0.68      0.48      0.56       331\n",
            "    B-Reason       0.48      0.12      0.19       306\n",
            "     B-Route       0.43      0.26      0.32       139\n",
            "  B-Strength       0.68      0.73      0.70       427\n",
            "       I-ADE       0.38      0.05      0.09        60\n",
            "    I-Dosage       0.70      0.38      0.49       237\n",
            "      I-Drug       0.73      0.68      0.70       257\n",
            "  I-Duration       0.70      0.42      0.52        76\n",
            "      I-Form       0.81      0.79      0.80       233\n",
            " I-Frequency       0.60      0.63      0.61       877\n",
            "    I-Reason       0.31      0.09      0.14       280\n",
            "     I-Route       0.75      0.21      0.33        14\n",
            "  I-Strength       0.65      0.71      0.68       400\n",
            "           O       0.97      0.98      0.98     78410\n",
            "\n",
            "    accuracy                           0.95     83584\n",
            "   macro avg       0.62      0.45      0.49     83584\n",
            "weighted avg       0.95      0.95      0.95     83584\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "y_pred_test = crf.predict(X_test)\n",
        "report = flat_classification_report(y_pred=y_pred_test, y_true=y_test)\n",
        "print(report)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_PBJc9BEWc5j",
        "outputId": "2766c38b-a12e-4258-f02b-a71852ab9d49"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tSCjaMvEWc5k"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}